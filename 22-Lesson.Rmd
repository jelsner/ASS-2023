# Thursday December 1, 2022 {.unnumbered}

**“Practice any art, music, singing, dancing, acting, drawing, painting, sculpting, poetry, fiction, essays, reportage, no matter how well or badly, not to get money & fame, but to experience becoming, to find out what's inside you, to make your soul grow.”** - Kurt Vonnegut

Today

- Interpolating to areal units
- Simulating spatial fields
- Interpolating multiple variables
- Machine learning for spatial interpolation

## Interpolating to areal units (block kriging) {-}

In 2008 tropical cyclone (TC) Fay formed from a tropical wave near the Dominican Republic, passed over the island of Hispaniola, Cuba, and the Florida Keys, then crossed the Florida peninsula and moved westward across portions of the Panhandle producing heavy rains in parts of the state.

Rainfall is an example of geostatistical data. In principle it can be measured anywhere, but typically you have values at a sample of sites. The pattern of observation sites is not of much interest as it is a consequence of constraints (convenience, opportunity, economics, etc) unrelated to the phenomenon. Interest centers on inference about how much rain fell across the region.

Storm total rainfall amounts from stations in and around the state are in `FayRain.txt` on my website. They are compiled reports from official weather sites and many cooperative sites. The cooperative sites are the Community Collaborative Rain, Hail and Snow Network (CoCoRaHS), a community-based, high density precipitation network made up of volunteers who take measurements of precipitation in their yards. The data were obtained from NOAA/NCEP/HPC and from the Florida Climate Center.

Import the data.
```{r}
L <- "http://myweb.fsu.edu/jelsner/temp/data/FayRain.txt"
( FR.df <- readr::read_table(L) )
```

The data frame contains 803 rainfall sites. Longitude and latitude coordinates of the sites are given in the first two columns and total rainfall in inches and millimeters are given in the second two columns. 

Create a spatial points data frame by specifying columns that contain the spatial coordinates. Then assign a geographic coordinate system and convert the rainfall from millimeters to centimeters.

```{r}
FR.sf <- sf::st_as_sf(x = FR.df,
                      coords = c("lon", "lat"),
                      crs = 4326) |>
  dplyr::mutate(tpm = tpm/10)

summary(FR.sf$tpm)
```

The median rainfall across all available observations is 15.8 cm and the highest is 60.2 cm. 

Get the Florida county boundaries from the {USAboundaries} package.

```{r}
FL.sf <- USAboundaries::us_counties(states = "Florida")
```

Transform the geographic coordinates of the site locations and map polygons to projected coordinates. Here you use Florida GDL Albers (EPSG:3087) with meter as the length unit.
```{r}
FR.sf <- sf::st_transform(FR.sf, crs = 3087)
FL.sf <- sf::st_transform(FL.sf, crs = 3087)
sf::st_crs(FR.sf)
```

Start by making a map of the rainfall sites and storm total rainfall that includes the state border.

```{r}
tmap::tm_shape(FR.sf) +
  tmap::tm_dots(col = "tpm", size = .5) +
tmap::tm_shape(FL.sf) +
  tmap::tm_borders()
```

Two areas of very heavy rainfall are noted. One running north-south along the east coast and another across the north. 

Rainfall reporting sites are clustered in and around cities and are located only over land. This type of station location arrangement will make it hard for deterministic interpolation methods (e.g., IDW or splines) to produce a reasonable surface.

The empirical variogram is computed using the `variogram()` function from the {gstat} package. The first argument is the model formula specifying the rainfall column from the data frame and the second argument is the data frame name.  Here `~ 1` in the model formula indicates no covariates or trends in the data. Trends are included by specifying coordinate names through the `st_coordinates()` function.

Compute the empirical variogram for these set of rainfall values. Use a cutoff distance of 400 km (400,000 m). The cutoff is the separation distance up to which point pairs are included in the semivariogram. The smaller the cutoff value the more the variogram is focused on nearest neighbor locations.

```{r}
library(gstat)

v <- variogram(tpm ~ 1, 
               data = FR.sf,
               cutoff = 400000)
```

Plot the variogram values as a function of lag distance and add text indicating the number of point pairs for each lag distance. Save a copy of the plot for later.

```{r}
library(ggplot2)

v.df <- data.frame(dist = v$dist/1000,
                   gamma = v$gamma,
                   np = v$np)

( pv <- ggplot(v.df, aes(x = dist, y = gamma)) +
  geom_point() +
  geom_text(aes(label = np), nudge_y = -5) +
  scale_y_continuous(limits = c(0, 220)) +
  scale_x_continuous(limits = c(0, 400)) +
  xlab("Lagged distance (h) [km]") +
  ylab(expression(paste("Semivariance (", gamma, ") [", cm^2, "]"))) +
  theme_minimal() )
```

Values start low (around 50 cm$^2$) at the shortest lag distance and increase to greater than 200 cm$^2$ at lag distances of 200 km and longer.

The semivariance a lag zero is called the 'nugget' and the semivariance at a level where the variogram values no longer increase is called the 'sill.' The difference between the sill and the nugget is called the 'partial sill'.  The lag distance out to where the sill is reached is called the 'range.'  These three parameters (nugget, partial sill, and range) are used to model the variogram.

Next fit a model to the empirical variogram. The model is a mathematical relationship that defines the semivariance as a function of lag distance. First save the family and the initial parameter guesses in a variogram model (`vmi`) object.

```{r}
vmi <- vgm(model = "Gau", 
           psill = 150, 
           range = 200 * 1000, 
           nugget = 50)
vmi
```

The `psill` argument is the partial sill (the difference between the sill and the nugget) along the vertical axis. Estimate the parameter values by looking at the empirical variogram. 

Next use the `fit.variogram()` function to improve the fit over these initial values. Given a set of initial parameter values the method of weighted least squares is used to improve the parameter estimates.

```{r}
vm <- fit.variogram(object = v, 
                    model = vmi)
vm
```

The result is a variogram model with a nugget of 46.6 cm$^2$, a partial sill of 156 cm$^2$, and a range on the sill of 128 km. 

Plot the model on top of the empirical variogram. Let $r$ be the range, $c$ the partial sill and $c_o$ the nugget, then the equation defining the function over the set of lag distances $h$ is

$$
\gamma(h)=c\left(1-\exp\left(-\frac{h^2}{r^2}\right)\right)+c_o
$$

Create a data frame with values of h and gamma using this equation.

```{r}
nug <- vm$psill[1]
ps <- vm$psill[2]
r <- vm$range[2] / 1000
h <- seq(0, 400, .2)
gamma <- ps * (1 - exp(-h^2 / (r^2))) + nug

vm.df <- data.frame(dist = h,
                    gamma = gamma)

pv + geom_line(aes(x = dist, y = gamma), data = vm.df)
```

Check for anisotropy. Anisotropy refers to a dependence of the variogram shape on the direction of the location pairs used to compute semivariances. Isotropy refers to a directional independence.

```{r}
plot(variogram(tpm ~ 1, 
               data = FR.sf, 
               alpha = c(0, 45, 90, 135),
               cutoff = 400000), 
     xlab = "Lag Distance (m)")
```

The semivariance values reach the sill at a longer range  (about 300 km) in the north-south direction (0 degrees) compared to the other three directions.

Another way to look at directional dependence in the variogram is through a variogram map. Instead of classifying point pairs Z(s) and Z(s + h) by direction and distance class separately, you classify them jointly.

If h = {x, y} is the two-dimensional coordinates of the separation vector, in the variogram map the variance contribution of each point pair (Z(s) − Z(s + h))^2 is attributed to the grid cell in which h lies. The map is centered at (0, 0) and h is lag distance. Cutoff and width correspond to map extent and cell size; the semivariance map is point symmetric around (0, 0), as γ(h) = γ(−h).

The variogram map is made with the `variogram()` function by adding the `map = TRUE` argument. Here you set the cutoff to be 200 km (200,000 m) and the width (cell size) to be 20 km.

```{r}
vmap <- variogram(tpm ~ 1, 
                  data = FR.sf,
                  cutoff = 200000,
                  width = 20000,
                  map = TRUE)
plot(vmap)
```

The variogram map is centered on dx = 0 and dy = 0. Along the dx = 0 vertical line in the north-south direction (top-to-bottom on the plot) the semivariance values increase away from dy = 0, but the increase is less compared to along the dy = 0 horizontal line in the east-west direction (left-to-right on the plot) indicative of directional dependency.

You refit the variogram model defining an anisotropy ellipse with the `anis =` argument. The first parameter is the direction of longest range (here north-south) and the second parameter is the ratio of the longest to shortest ranges. Here about (200/300 = .67).

```{r}
vmi <- vgm(model = "Gau", 
           psill = 150, 
           range = 300 * 1000, 
           nugget = 50,
           anis = c(0, .67))
vm <- fit.variogram(v, vmi)
```

Use the variogram model together with the rainfall values at the observation sites to create an interpolated surface. Here you use ordinary kriging as there are no spatial trends in the rainfall.

Interpolation is done using the `krige()` function. The first argument is the model specification and the second is the data. Two other arguments are needed. One is the variogram model using the argument name `model =` and the other is a set of locations identifying where the interpolations are to be made. This is specified with the argument name `newdata =`.

Here you interpolate to locations on a regular grid. You create a grid of locations within the borders of the state using the `st_sample()` function.

```{r}
grid.sf <- sf::st_sample(FL.sf,
                         size = 5000,
                         type = "regular")
```

You specify the number of grid locations using the argument `size =`. Note that the actual number of locations will be somewhat different because of the irregular boundary.

First use the `krige()` function to interpolate the observed rainfall to the grid locations. For a given location, the interpolation is a weighted average of the rainfall across the entire region where the weights are determined by the variogram model.

```{r}
r.int <- krige(tpm ~ 1, 
               locations = FR.sf, 
               newdata = grid.sf,
               model = vm)
```

If the variogram model is not included then inverse distance-weighted interpolation is performed. The function will not work if different values share the same location.

The saved object (`r.int`) inherits the spatial geometry specified in the `newdata =` argument but extends it to a spatial data frame. The column `var1.pred` in the data frame is the interpolated rainfall and the second `var1.var` is the variability about the interpolated value.

Plot the interpolated storm-total rainfall field.

```{r}
tmap::tm_shape(r.int) +
  tmap::tm_dots("var1.pred",
                size = .1,
                palette = "Greens",
                title = "Rainfall (cm)") +
  tmap::tm_shape(FL.sf) +
  tmap::tm_borders() +
  tmap::tm_layout(legend.position = c("left", "bottom"),
                  title = "TC Fay (2008)",
                  title.position = c("left", "bottom"),
                  legend.outside = TRUE)
```

Note: a portion of the data locations are outside of the state but interest is only interpolated values within the state border as specified by the `newdata =` argument.

The spatial interpolation shows that parts of east central and north Florida were deluged by Fay with rainfall totals exceeding 30 cm (12 in).

Block kriging

The interpolation can also be done as an area average. For example what was the storm-total average rainfall for each county?

County level rainfall is relevant for water resource managers. Block kriging produces an estimate of this area average, which will differ from a simple average over all sites within the county because of the spatial autocorrelation in rainfall observations.

You use the same function to interpolate but specify the spatial polygons rather than the spatial grid as the new data. Here the spatial polygons are the county borders.

```{r}
r.int2 <- krige(tpm ~ 1, 
                locations = FR.sf, 
                newdata = FL.sf, 
                model = vm)
```

Again plot the interpolations.

```{r}
tmap::tm_shape(r.int2) +
  tmap::tm_polygons(col = "var1.pred",
                    palette = "Greens",
                    title = "Rainfall (cm)") +
  tmap::tm_layout(legend.position = c("left", "bottom"),
                  title = "TC Fay (2008)",
                  title.position = c("left", "bottom"))
```

The overall pattern of rainfall from Fay featuring the largest amounts along the central east coast and over the Big Bend region are similar in both maps but these estimates answer questions like on average how much rain fell over Leon County during TC Fay? 

You compare the kriged average with the simple average at the county level with the `aggregate()` method. The argument `FUN = mean` says to compute the average of the values in `FR.sf` across the polygons in `FL.sf`.

```{r}
r.int3 <- aggregate(FR.sf, 
                    by = FL.sf, 
                    FUN = mean)
```

The result is a simple feature data frame of the average rainfall in each county.

The state-wide mean of the kriged estimates at the county level is

```{r}
round(mean(r.int2$var1.pred), 2)
```

This compares with a state-wide mean from the simple averages.

```{r}
round(mean(r.int3$tpm), 2)
```

The correlation between the two estimates across the 67 counties is 

```{r}
round(cor(r.int3$tpm, r.int2$var1.pred), 2)
```

The variogram model reduces the standard deviation of the kriged estimate relative to the standard deviation of the simple averages because of the local smoothing.

```{r}
round(sd(r.int2$var1.pred), 2)
round(sd(r.int3$tpm), 2)
```

This can be seen with a scatter plot of simple averages versus kriged averages at the county level.

```{r}
compare.df <- data.frame(simpleAvg = r.int3$tpm,
                         krigeAvg = r.int2$var1.pred)
ggplot(compare.df, aes(x = simpleAvg,
                       y = krigeAvg)) +
  geom_point() +
  geom_abline(slope = 1) +
  geom_smooth(method = lm, se = FALSE)
```

An advantage of kriging as a method of spatial interpolation is the accompanying uncertainty estimates. The prediction variances are listed in a column in the spatial data frame saved from apply the `krige()` function. Variances are smaller in regions with more rainfall observations.  

Prediction variances are also smaller with block kriging as much of the variability within the county averages out. To compare the distribution characteristics of the prediction variances for the point and block kriging of the rainfall observations, type

```{r}
round(summary(r.int$var1.var), 1)
round(summary(r.int2$var1.var), 1)
```

The median prediction variance (in cm$^2$) for the point kriging is close to the value of the nugget.

```{r}
round(fivenum(r.int$var1.var)[3], 1)
```

In contrast, the median prediction variance for our block kriging is a much smaller.

```{r} 
round(fivenum(r.int2$var1.var)[3], 1)
```

## Simulating spatial fields {-}

Simulations use this uncertainty to provide additional data for deterministic models. Suppose for example you have a hydrology model of rainfall runoff. Given a spatial field of rain amounts the model predicts a discharge rate at some location along a river. The uncertainty in the predicted runoff rate at the location is due to the uncertainty in where and how hard the rain fell (in the rainfall field) and not due to the deterministic hydrology model.

The uncertainty in the rainfall field is simulated conditional on the observations with the same `krige()` function by adding the argument `nsim =` that specifies the number of simulations.  

For a large number it may be necessary to limit the number neighbors in the kriging. This is done using the `nmax` argument. For a given location, the weights assigned to observations far away are very small, so it is efficient to limit how many are used in the simulation.

As an example, here you generate four realizations of the county-level average storm total rainfall for Fay and limit the neighborhood to 50 of the closest observation sites. This takes a few seconds.

```{r}
r.sim <- krige(tpm ~ 1, 
               locations = FR.sf, 
               newdata = FL.sf, 
               model = vm, 
               nsim = 4, 
               nmax = 50)
```

Given the variogram model, the simulations are conditional on the observed rainfall.

```{r}
tmap::tm_shape(r.sim) +
    tmap::tm_polygons(col = c("sim1", "sim2", "sim3", "sim4"),
                palette = "Greens",
                title = "Simulated Rainfall [cm]") +
    tmap::tm_facets(free.scales = FALSE) 
```

The overall pattern of rainfall remains the same, but there are differences especially in counties with fewer observations and in counties where the rainfall gradients are sharp.

## Interpolating multiple variables {-}

Spatial interpolation can be extended to obtain surfaces of multiple variables. The idea is that if two field variables are correlated then information about the spatial correlation in one field variable can help provide information about values in the other field variable. The spatial variability of one variable is correlated with the spatial variability of the other variable. And this idea is not limited to two variables. 

Here you consider observations of heavy metal concentrations (ppm) in the top soil in the flood plain of the river Meuse near the village of Stein. The data are available in {sp} package.

```{r}
library(sp)

data(meuse)
names(meuse)
```

The metals include cadmium, copper, lead, and zinc. Observation locations are given by x and y. Other variables include elevation, soil type and distance to the river.

Create a simple feature data frame with a projected coordinate system for the Netherlands.

```{r}
meuse.sf <- sf::st_as_sf(x = meuse,
                         coords = c("x", "y"),
                         crs = 28992)
```

Interest is on the spatial distribution of all four heavy metals in the soil.

Map the concentrations at the observation locations.

```{r}
tmap::tmap_mode("view")
tmap::tm_shape(meuse.sf) +
  tmap::tm_dots(col = c("cadmium", "copper", "lead", "zinc"))
```

All observations (bulk sampled from an area of approximately 15 m x 15 m) have units of ppm. The most abundant heavy metal is zinc followed by lead and copper. For all metals highest concentrations are found nearest to the river. Thus you want to include distance to river as a covariate (trend term) and use universal kriging.

The distribution of concentrations is skewed with many locations having only low levels of heavy metals with a few having very high levels.

```{r}
ggplot(data = meuse.sf,
       mapping = aes(x = lead)) +
  geom_histogram(bins = 17) +
  theme_minimal()
```

Thus you use a logarithmic transformation.

First you organize the data as a `gstat` object. This is done with the `gstat()` function which orders (and copies) the variables into a single object. Ordering is done successively.

Here you specify the trend using the square root of the distance to river and take the natural logarithm of the heavy metal concentration. You give the dependent variable a new name with the `id =` argument.

```{r}
g <- gstat(id = "logCd", 
           formula = log(cadmium) ~ sqrt(dist), 
           data = meuse.sf)
g <- gstat(g, 
           id = "logCu", 
           formula = log(copper) ~ sqrt(dist), 
           data = meuse.sf)
g <- gstat(g, 
           id = "logPb", 
           formula = log(lead) ~ sqrt(dist), 
           data = meuse.sf)
g <- gstat(g, 
           id = "logZn",
           formula = log(zinc) ~ sqrt(dist), 
           data = meuse.sf)
g
```

Next you use the `variogram()` function to compute empirical variograms. The function, when operating on a `gstat` object, computes all direct and cross variograms.

```{r}
v <- variogram(g)
plot(v)
```

The plot method displays the set of direct and cross variograms. The direct variograms are shown in the four panels along the diagonal of the triangle of plots.

The cross variograms are shown in the six panels below the diagonal. For example, the cross variogram between the values of cadmium and copper is given in the second row of the first column and so on. 

The cross variogram is analogous to the multi-type $K$ function for analyzing point pattern data.

The cross variograms show small semivariance values at short lag distance with increasing semivariance values at longer lags. Because these variables are co-located, you can also compute direct correlations.

```{r}
cor(meuse[c("cadmium", "copper", "lead", "zinc")])
```

The direct correlation between cadmium and copper is .92 and between cadmium and lead is .8.

The correlation matrix confirms strong cross correlation among the four variables at zero lag. The cross variogram generalizes these correlations across lag distance. For instance, the cross variogram indicates the strength of the relationship between cadmium at one location and copper at nearby locations.

You use the `fit.lmc()` function to fit separate variogram models to each of the empirical variograms. You use an initial partial sill of .5, an initial nugget of zero and an initial range of 800 meters.
```{r}
vm <- fit.lmc(v, g, 
              vgm(model = "Sph", 
                  psill = .5,
                  nugget = 0,
                  range = 800))
plot(v, vm)
```

The final variogram models (blue line) fit the empirical variogram (direct and cross) well.

Given the variogram models, co-kriged maps are produced using the `predict()` method after setting the grid locations for the interpolations. The CRS for the grid locations must match the CRS of the data.

```{r}
data(meuse.grid)

grid.sf <- sf::st_as_sf(x = meuse.grid,
                        coords = c("x", "y"),
                        crs = 28992)

hm.int <- predict(vm, grid.sf)
names(hm.int)
```

Plot the interpolated for logarithm of zinc concentration are plotted.
```{r}
tmap::tmap_mode("plot")
tmap::tm_shape(hm.int) +
  tmap::tm_dots(col = c("logCd.pred", "logCu.pred", "logPb.pred", "logZn.pred"), 
                size = .2, breaks = seq(-2, 8, by = 1), palette = "Reds", midpoint = NA)
```

The pattern of heavy metal concentrations are similar with highest values along the river bank. 

Compare with predictions using only cadmium
```{r}
v2 <- variogram(log(cadmium) ~ sqrt(dist), 
                data = meuse.sf)
vm2 <- fit.variogram(v2, vgm(psill = .15, model = "Sph", 
                             range = 800, nugget = .1))
int <- krige(log(cadmium) ~ sqrt(dist), meuse.sf, newdata = grid.sf, 
                 model = vm2)

p1 <- tmap::tm_shape(int) +
        tmap::tm_dots(col = "var1.pred", 
                      size = .2, palette = "Reds", breaks = seq(-2, 3, by = .5))
p2 <- tmap::tm_shape(hm.int) +
        tmap::tm_dots(col = "logCd.pred", 
                      size = .2, palette = "Reds", breaks = seq(-2, 3, by = .5))
tmap::tmap_arrange(p1, p2)

cor(hm.int$logCu.pred, int$var1.pred)
```

Only minor differences are visible on the plot and the correlation between the two interpolations exceeds .9.

Plot the covariances between zinc and cadmium.

```{r}
tmap::tm_shape(hm.int) +
  tmap::tm_dots(col = "cov.logCd.logZn", size = .2)
```

The map shows areas of the flood plain with high (and low) correlations between cadmium and zinc. Caution: Higher values of the covariance indicate lower correlations. There is an inverse relationship between the correlogram and the covariogram.

Obtaining a quality statistical spatial interpolation is a nuanced process but with practice kriging can be an important tool in your toolbox.

Kriging is useful tool for ‘filling in the gaps’ between sampling sites. Handy if you want to make a map, or need to match up two spatial data sets that overlap in extent, but have samples at different locations.

## Machine learning for spatial interpolation {-}

See https://geocompr.robinlovelace.net/spatial-cv.html
